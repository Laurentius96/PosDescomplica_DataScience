{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Resumo Integrado sobre Aplicações Estatísticas\n",
        "\n",
        "---\n",
        "\n",
        "## Aula 01: Redes Bayesianas\n",
        "\n",
        "### Introdução\n",
        "\n",
        "Redes Bayesianas são modelos gráficos probabilísticos que representam relações de dependência entre variáveis por meio de um gráfico acíclico direcionado (DAG). Elas combinam conceitos de teoria de grafos e estatística bayesiana, sendo amplamente utilizadas para modelar incertezas em diversos cenários.\n",
        "\n",
        "### Conceitos Principais\n",
        "\n",
        "- **Nós:** Representam variáveis aleatórias.\n",
        "- **Arestas:** Indicam as dependências condicionais entre variáveis.\n",
        "- **Teorema de Bayes:** Base para a atualização das probabilidades condicionais.\n",
        "\n",
        "### Exemplo Prático\n",
        "\n",
        "Imagine que você trabalha com detecção de fraudes em transações bancárias. Usando uma Rede Bayesiana, você pode modelar a probabilidade de fraude considerando variáveis como o valor da transação, o país de origem e o histórico de compras do cliente.\n",
        "\n",
        "**Exemplo em Python (Detecção de Fraude):**\n",
        "\n",
        "```python\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Carregando o dataset Iris\n",
        "iris = load_iris()\n",
        "X = iris.data  # Características das flores\n",
        "y = iris.target  # Tipos de flores\n",
        "\n",
        "# Dividindo os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Criando o classificador Naive Bayes\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Treinando o modelo\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões com os dados de teste\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Avaliando a acurácia do modelo\n",
        "accuracy = (y_pred == y_test).sum() / len(y_test)\n",
        "print(f'Acurácia do classificador Naive Bayes: {accuracy:.2f}')\n",
        "```\n",
        "\n",
        "**Explicação dos Passos:**\n",
        "\n",
        "1. **Carregamento do Dataset:** Utilizamos o dataset `Iris`, que contém dados sobre três tipos de flores.\n",
        "2. **Divisão em Treino e Teste:** Os dados são divididos em conjuntos de treino (75%) e teste (25%).\n",
        "3. **Criação do Modelo:** Usamos o classificador Naive Bayes, que é um caso especial de Rede Bayesiana.\n",
        "4. **Treinamento:** O modelo é treinado com os dados de treino.\n",
        "5. **Previsão e Avaliação:** Fazemos previsões nos dados de teste e avaliamos a acurácia do modelo.\n",
        "\n",
        "### Exercício Prático de Python\n",
        "\n",
        "Crie uma Rede Bayesiana simples utilizando a biblioteca `pgmpy`, que modele a probabilidade de uma pessoa estar gripada, dado sintomas como febre e dor de garganta.\n",
        "\n",
        "---\n",
        "\n",
        "## Aula 02: Multi-Armed Bandit (MAB)\n",
        "\n",
        "### Introdução\n",
        "\n",
        "O problema do **Multi-Armed Bandit (MAB)** é um dos desafios clássicos de otimização e aprendizado por reforço, onde o objetivo é maximizar a recompensa acumulada ao longo do tempo. Ele é modelado como um conjunto de \"braços\" de uma máquina caça-níqueis, cada um com uma distribuição de recompensas desconhecida.\n",
        "\n",
        "### Conceitos Principais\n",
        "\n",
        "- **Exploração x Exploração:** O equilíbrio entre explorar novas opções e explorar aquelas que já se mostraram promissoras.\n",
        "- **Algoritmos Comuns:** Epsilon-greedy, UCB (Upper Confidence Bound), Thompson Sampling.\n",
        "\n",
        "### Exemplo Prático\n",
        "\n",
        "Imagine que você está otimizando uma campanha de marketing digital. O MAB ajuda a determinar qual versão do anúncio traz o melhor retorno, ao mesmo tempo em que continua explorando novas possibilidades.\n",
        "\n",
        "**Exemplo em Python (Simulação de MAB):**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Simulação de um problema de MAB com 3 anúncios\n",
        "recompensas = [0.1, 0.2, 0.15]  # Taxa de sucesso de cada anúncio\n",
        "\n",
        "# Escolhendo um anúncio aleatoriamente com base nas probabilidades\n",
        "escolha = np.random.choice([0, 1, 2], p=[0.3, 0.4, 0.3])\n",
        "\n",
        "print(f\"Escolha do anúncio: {escolha}, Recompensa esperada: {recompensas[escolha]}\")\n",
        "```\n",
        "\n",
        "**Explicação dos Passos:**\n",
        "\n",
        "1. **Definição das Recompensas:** Cada anúncio tem uma taxa de sucesso diferente.\n",
        "2. **Escolha Aleatória:** Escolhemos um anúncio com base nas probabilidades atribuídas a cada um.\n",
        "3. **Exibição do Resultado:** Mostramos qual anúncio foi escolhido e qual a recompensa esperada.\n",
        "\n",
        "### Exercício Prático de Python\n",
        "\n",
        "Implemente um algoritmo Epsilon-greedy para resolver um problema Multi-Armed Bandit. Simule um ambiente com diferentes probabilidades de recompensa para cada braço.\n",
        "\n",
        "---\n",
        "\n",
        "## Aula 03: Cadeias de Markov\n",
        "\n",
        "### Introdução\n",
        "\n",
        "As Cadeias de Markov são modelos probabilísticos que descrevem sistemas que mudam de estado ao longo do tempo, onde a transição para o próximo estado depende apenas do estado atual e não dos estados anteriores (propriedade de Markov). Elas são amplamente utilizadas em análise preditiva e modelagem de processos estocásticos.\n",
        "\n",
        "### Conceitos Principais\n",
        "\n",
        "- **Estados:** Representam as diferentes condições possíveis do sistema.\n",
        "- **Matriz de Transição:** Define a probabilidade de mover-se de um estado para outro.\n",
        "- **Cadeias de Markov em Tempo Contínuo:** Utilizadas em áreas como telecomunicações e biologia.\n",
        "\n",
        "### Exemplo Prático\n",
        "\n",
        "Suponha que você esteja modelando o comportamento de um cliente em um website. Cada página que ele visita pode ser representada como um estado, e as probabilidades de transição entre as páginas podem ser modeladas como uma cadeia de Markov.\n",
        "\n",
        "**Exemplo em Python (Simulação de Cadeia de Markov):**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Matriz de transição de estados para um website com três páginas\n",
        "matriz_transicao = np.array([[0.1, 0.6, 0.3],\n",
        "                             [0.4, 0.3, 0.3],\n",
        "                             [0.2, 0.2, 0.6]])\n",
        "\n",
        "# Estado inicial (ex: Página inicial do site)\n",
        "estado_atual = 0\n",
        "\n",
        "# Simulação de transição de estado\n",
        "estado_proximo = np.random.choice([0, 1, 2], p=matriz_transicao[estado_atual])\n",
        "print(f\"Estado atual: {estado_atual}, Próximo estado: {estado_proximo}\")\n",
        "```\n",
        "\n",
        "**Explicação dos Passos:**\n",
        "\n",
        "1. **Definição da Matriz de Transição:** A matriz de transição define as probabilidades de passar de uma página para outra.\n",
        "2. **Estado Inicial:** O estado inicial é definido como a página inicial.\n",
        "3. **Simulação de Transição:** Simulamos a transição para o próximo estado com base na matriz de transição.\n",
        "\n",
        "### Exercício Prático de Python\n",
        "\n",
        "Implemente uma simulação de uma Cadeia de Markov para modelar o comportamento de um cliente navegando por diferentes páginas de um site. Use uma matriz de transição e simule a navegação em 100 passos.\n",
        "\n",
        "---\n",
        "\n",
        "## Aula 04: Saiba Mais\n",
        "\n",
        "### Introdução\n",
        "\n",
        "Esta aula traz uma visão mais ampla das aplicações estatísticas, explorando ferramentas avançadas e casos de uso em diferentes setores. O foco está em aplicações práticas e na integração de várias técnicas estatísticas para resolver problemas reais.\n",
        "\n",
        "### Recursos Adicionais\n",
        "\n",
        "- **Leituras Recomendadas:**\n",
        "  - \"Probabilistic Graphical Models: Principles and Techniques\" de Daphne Koller.\n",
        "  - \"Reinforcement Learning: An Introduction\" de Richard S. Sutton e Andrew G. Barto.\n",
        "  - \"Markov Chains: From Theory to Implementation and Experimentation\" de Paul A. Gagniuc.\n",
        "\n",
        "---\n",
        "\n",
        "## Mapa Mental Detalhado\n",
        "\n",
        "### Aplicações Estatísticas\n",
        "\n",
        "#### Redes Bayesianas\n",
        "- **Definição:** Modelos gráficos probabilísticos que representam variáveis e suas dependências condicionais.\n",
        "- **Componentes:**\n",
        "  - **Nós:** Representam variáveis aleatórias.\n",
        "  - **Arestas:** Dependências condicionais.\n",
        "  - **Teorema de Bayes:** Atualiza probabilidades com base em novas evidências.\n",
        "- **Aplicações:**\n",
        "  - Diagnóstico médico.\n",
        "  - Detecção de fraudes.\n",
        "  - Sistemas de recomendação.\n",
        "\n",
        "#### Multi-Armed Bandit (MAB)\n",
        "- **Definição:** Problema de otimização que busca equilibrar exploração e exploração para maximizar a recompensa acumulada.\n",
        "- **Estratégias:**\n",
        "  - Epsilon-greedy.\n",
        "  - UCB (Upper Confidence Bound).\n",
        "  - Thompson Sampling.\n",
        "- **Aplicações:**\n",
        "  - Otimização de campanhas de marketing.\n",
        "  - Testes A/B.\n",
        "  - Sistemas de recomendação.\n",
        "\n",
        "#### Cadeias de Markov\n",
        "- **Definição:** Modelos probabilísticos para processos que mudam de estado ao longo do tempo, onde a transição depende apenas do estado atual.\n",
        "- **Componentes:**\n",
        "  - Estados.\n",
        "  - Matriz de Transição.\n",
        "- **Aplicações:**\n",
        "  - Previsão de demanda.\n",
        "\n",
        "\n",
        "  - Análise de tráfego de rede.\n",
        "  - Modelagem de comportamento de usuários.\n",
        "\n",
        "---\n",
        "\n",
        "## Resumo para Revisão\n",
        "\n",
        "- **Redes Bayesianas:** Modelos gráficos que utilizam o Teorema de Bayes para atualizar probabilidades. Utilizadas em diagnósticos médicos e detecção de fraudes.\n",
        "- **Multi-Armed Bandit (MAB):** Algoritmo de aprendizado por reforço que otimiza recompensas. Aplicado em testes A/B e marketing.\n",
        "- **Cadeias de Markov:** Modelos que descrevem transições entre estados ao longo do tempo. Utilizados em previsões de demanda e análise de tráfego.\n",
        "\n",
        "---\n",
        "\n",
        "## Material Complementar\n",
        "\n",
        "**Questões de Múltipla Escolha:**\n",
        "\n",
        "1. O que são Redes Bayesianas?\n",
        "   - a) Modelos gráficos que representam dependências condicionais entre variáveis.\n",
        "   - b) Algoritmos de aprendizado supervisionado.\n",
        "   - c) Modelos determinísticos para predição de eventos.\n",
        "   - d) Redes neurais profundas.\n",
        "   - e) Algoritmos de regressão linear.\n",
        "\n",
        "2. Qual é o objetivo do problema Multi-Armed Bandit?\n",
        "   - a) Maximizar a recompensa acumulada ao longo do tempo.\n",
        "   - b) Minimizar o risco de um investimento.\n",
        "   - c) Otimizar a previsão de demanda.\n",
        "   - d) Prever a classificação de dados.\n",
        "   - e) Avaliar a acurácia de um modelo.\n",
        "\n",
        "3. O que caracteriza uma Cadeia de Markov?\n",
        "   - a) A transição para o próximo estado depende apenas do estado atual.\n",
        "   - b) A transição depende de todos os estados anteriores.\n",
        "   - c) Os estados são completamente independentes.\n",
        "   - d) A cadeia não possui estados iniciais.\n",
        "   - e) A transição entre estados não segue uma probabilidade fixa.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6QUifNd0l-lV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl7kzg5Rl9Aj"
      },
      "outputs": [],
      "source": []
    }
  ]
}